{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daaca78e",
   "metadata": {},
   "source": [
    "# Regresión Lineal Múltiple (dos o más variables de entrada)\n",
    "\n",
    "## Ejercicio 6\n",
    "\n",
    "Utilice los scripts disponibles en la teoría y práctica para entrenar un combinador lineal.  \n",
    "El modelo debe recibir tres dígitos binarios y retornar la representación decimal del número que resulta de la combinación de dígitos (para las entradas 000, 010 y 101 debe obtener las salidas 0, 2 y 5, respectivamente).\n",
    "\n",
    "a) Utilizando el bias o peso W0 (comportamiento normal).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed2ebbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio con bias:  0.33266354543478815\n",
      "Iteraciones con bias: 174\n",
      "Valor del arco del bias:  [0.01477993]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Fuentes.ClassNeuronaGral import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "ALPHA = 0.05\n",
    "MAX_ITE = 10000\n",
    "COTA = 10e-6\n",
    "\n",
    "X = np.array([[0,0,0],\n",
    "\t\t\t[0,1,0],\n",
    "\t\t\t[1,0,1]])\n",
    "\n",
    "T = np.array([[0],\n",
    "\t\t\t[2],\n",
    "\t\t\t[5]])\n",
    "\n",
    "data_scaler , targer_scaler= MinMaxScaler(), MinMaxScaler()\n",
    "X = data_scaler.fit_transform(X)\n",
    "T = targer_scaler.fit_transform(T)\n",
    "\n",
    "\n",
    "ng = NeuronaGradiente(alpha=ALPHA, n_iter=MAX_ITE, cotaE=COTA, FUN='linear', title=['bits','decimal'])\n",
    "ng.fit(X, T)\n",
    "\n",
    "Y_pred = ng.predict_nOut(X)\n",
    "print(\"Error cuadrático medio con bias: \", np.mean((T - Y_pred)**2))\n",
    "print(\"Iteraciones con bias:\", ng.iterations_)\n",
    "print(\"Valor del arco del bias: \", ng.b_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f98acf",
   "metadata": {},
   "source": [
    "### b) \n",
    "\n",
    "Utilizando únicamente las tres entradas correspondientes a los dígitos binarios anulando el bias o W0 del cálculo.  \n",
    "\n",
    "Compare la cantidad de iteraciones necesarias para obtener el vector de pesos correcto en ambos casos. Observe el valor del arco correspondiente al bias en a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c5a9841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadrático medio sin bias:  0.3381836648660692\n",
      "Iteraciones sin bias: 85\n",
      "Valor del arco del bias:  0\n"
     ]
    }
   ],
   "source": [
    "ng_no_bias = NeuronaGradiente(alpha=ALPHA, n_iter=MAX_ITE, cotaE=COTA, FUN='linear', title=['bits','decimal'], with_bias=False)\n",
    "\n",
    "ng_no_bias.fit(X, T)\n",
    "\n",
    "Y_pred = ng_no_bias.predict_nOut(X)\n",
    "print(\"Error cuadrático medio sin bias: \", np.mean((T - Y_pred)**2))\n",
    "print(\"Iteraciones sin bias:\", ng_no_bias.iterations_)\n",
    "print(\"Valor del arco del bias: \", ng_no_bias.b_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07cb881",
   "metadata": {},
   "source": [
    "> Conclusión: El bias es el encargado de desplazar las salidas, cómo en este caso no juega un rol tan importante puesto que la recta de la regresión lineal pasa cercana al origen, se lo puede no utilizar. La opción con bias converge más lentamente, porque tiene que ajustar también el bias para alcanzar la cota de error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
