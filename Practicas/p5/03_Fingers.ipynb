{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51c85f76",
   "metadata": {},
   "source": [
    "\n",
    "## Ejercicio 3\n",
    "\n",
    "Para resolver este ejercicio utilice un modelo de red neuronal convolucional que reconozca la cantidad de dedos extendidos en cada mano de las imágenes del dataset **“Fingers”**.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src='../../images/p4-ej10.png' width=\"40%\">\n",
    "</div>\n",
    "\n",
    "La versión original de este de estas imágenes se encuentra en https://www.kaggle.com/koryakinp/fingers.\n",
    "\n",
    "Puede hallar una versión reducida de estas imágenes en el Moodle del curso, en la misma sección donde se encuentra este enunciado de práctica. También encontrará allí ejemplos sobre cómo cargar estas imágenes y cómo procesarlas con una red neuronal convolucional.\n",
    "\n",
    "### a)\n",
    "\n",
    "Entrene y pruebe un modelo utilizando los datos de las carpetas **test** y **train**, midiendo **accuracy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eca333e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18000 files belonging to 6 classes.\n",
      "Using 14400 files for training.\n",
      "Found 18000 files belonging to 6 classes.\n",
      "Using 3600 files for validation.\n",
      "Found 3600 files belonging to 6 classes.\n",
      "Clases encontradas: ['0', '1', '2', '3', '4', '5']\n",
      "Número de clases: 6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definir rutas\n",
    "TRAIN_DIR = '../../Datos/fingers/train'\n",
    "TEST_DIR = '../../Datos/fingers/test'\n",
    "\n",
    "# Parámetros\n",
    "IMG_SIZE = (64, 64)  # Ajusta según tu dataset\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Cargar datasets automáticamente\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'  # Para clasificación multiclase\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST_DIR,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    shuffle=False  # Para mantener orden en test\n",
    ")\n",
    "\n",
    "# ¡OBTENER CLASES ANTES DE NORMALIZAR!\n",
    "class_names = train_dataset.class_names\n",
    "print(\"Clases encontradas:\", class_names)\n",
    "print(\"Número de clases:\", len(class_names))\n",
    "\n",
    "# Normalizar imágenes (0-1) DESPUÉS de obtener class_names\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_dataset = val_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_dataset = test_dataset.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae8c603",
   "metadata": {},
   "source": [
    "### b)\n",
    "\n",
    "Genere una versión del **dataset** para **test** agregando transformaciones al azar sobre imágenes originales. Haga **rotaciones** entre -45° y 45°, repita el test y mida el accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f38371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "044a2a6b",
   "metadata": {},
   "source": [
    "### c)\n",
    "\n",
    "Genere una versión del **dataset train** como en b) y repita el entrenamiento y prueba del punto a) con los datasets modificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c92cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
