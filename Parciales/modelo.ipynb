{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b7a6d00",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caf92bd6",
   "metadata": {},
   "source": [
    "#### a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64912f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores normalizados entre 0 y 1:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m values = [\u001b[32m300\u001b[39m, \u001b[32m250\u001b[39m, \u001b[32m30\u001b[39m, \u001b[32m200\u001b[39m]\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mValores normalizados entre 0 y 1:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28mprint\u001b[39m((\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mMIN\u001b[49m) / (MAX - MIN))\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mValores normalizados con media y desviación estándar:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m((values - MEAN) / STD)\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for -: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "MEAN = 126907\n",
    "STD = 41643\n",
    "MIN = 61\n",
    "MAX = 326\n",
    "\n",
    "values = [300, 250, 30, 200]\n",
    "\n",
    "print(\"Valores normalizados entre 0 y 1:\")\n",
    "print((values - MIN) / (MAX - MIN))\n",
    "\n",
    "print(\"Valores normalizados con media y desviación estándar:\")\n",
    "print((values - MEAN) / STD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3e7c3",
   "metadata": {},
   "source": [
    "#### b)\n",
    "\n",
    "Los linealizados: los valores dicen como se posicionan dentro del rango de valores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22973054",
   "metadata": {},
   "source": [
    "#### c)\n",
    "\n",
    "Los z-score: a cuantos desvios estandar estan los valores de la media."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef30598",
   "metadata": {},
   "source": [
    "#### d)\n",
    "\n",
    "La de media y desvio. Porque la linealizada sufre mucho con los valores extremos, ya que modifican como se mapean los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d3d415",
   "metadata": {},
   "source": [
    "# 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c3f99ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cálculo de la salida de un perceptrón:\n",
      "-0.4097999999999994\n",
      "Salida seleccionado:\n",
      "-0.4467999999999993\n",
      "Como ambas salidas son negativas, el perceptrón selecciona a este ejemplo.\n"
     ]
    }
   ],
   "source": [
    "W = {\n",
    "\t\"EDAD\": 0.392,\n",
    "\t\"ALTURA\": 0.001,\n",
    "\t\"HABILIDAD\": -2.441,\n",
    "\t\"BIAS\": 0.4022\n",
    "}\n",
    "\n",
    "EJEMPLO = {\n",
    "\t\"EDAD\": 10,\n",
    "\t\"ALTURA\": 150,\n",
    "\t\"HABILIDAD\": 2 # Media=2\n",
    "}\n",
    "\n",
    "#completar\n",
    "EJEMPLO_SELECCIONADO = {\n",
    "\t\"EDAD\": 16,\n",
    "\t\"ALTURA\": 202,\n",
    "\t\"HABILIDAD\": 3 # Media=2\n",
    "}\n",
    "\n",
    "#completar\n",
    "EJEMPLO_NO_SELECCIONADO = {\n",
    "\t\"EDAD\": 17,\n",
    "\t\"ALTURA\": 157,\n",
    "\t\"HABILIDAD\": 1 # Media=2\n",
    "}\n",
    "\n",
    "print(\"Cálculo de la salida de un perceptrón:\")\n",
    "salida = W[\"EDAD\"] * EJEMPLO[\"EDAD\"] + W[\"ALTURA\"] * EJEMPLO[\"ALTURA\"] + W[\"HABILIDAD\"] * EJEMPLO[\"HABILIDAD\"] + W[\"BIAS\"]\n",
    "print(salida)\n",
    "\n",
    "\n",
    "print(\"Salida seleccionado:\")\n",
    "salida_seleccionado = W[\"EDAD\"] * EJEMPLO_SELECCIONADO[\"EDAD\"] + W[\"ALTURA\"] * EJEMPLO_SELECCIONADO[\"ALTURA\"] + W[\"HABILIDAD\"] * EJEMPLO_SELECCIONADO[\"HABILIDAD\"] + W[\"BIAS\"]\n",
    "print(salida_seleccionado)\n",
    "\n",
    "print(\"Como ambas salidas son negativas, el perceptrón selecciona a este ejemplo.\")\n",
    "\n",
    "# Para saber si la salidas que dice que si o no tenemos que ver ejemplos que digan que si o no\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a54d6",
   "metadata": {},
   "source": [
    "# 2)\n",
    "\n",
    "\n",
    "Similitudes:\n",
    "- Todas calculan la salida neta de la misma forma (X*W).\n",
    "- No todas redes de una neurona.\n",
    "- Trabajan con aprendizaje supervisado.\n",
    "- Todos tienen bias.\n",
    "\n",
    "Diferencias:\n",
    "- La funcion de activacion cambia: escalon para perceptron, f(x)=x para combinador lineal y f(x)=sigmoid/tanh/etc para neurona no lineal.\n",
    "- El perceptron y neurona no lineal resuelve un problema de clasificacion. La neurona lineal solo resuleve problemas de regresion lineal.\n",
    "- El perceptron aprende de forma distinta, no usa descenso de gradiente, sino que lo hace con el vector proyeccion.\n",
    "\n",
    "> **Nota:** Podria preguntar un ejemplo de cuando funciona o no un tipo de neurona y otra. Podria preguntar por puntos en el plano y preguntar si un tipo de neurona puede funcionar o no para clasificacion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1bc520",
   "metadata": {},
   "source": [
    "# 3)\n",
    "\n",
    "## a y b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc772b0",
   "metadata": {},
   "source": [
    "|      |  T1  | T2  | T3  |    Recall     |\n",
    "| :--: | :--: | :-: | :-: | :-----------: |\n",
    "|  T1  |  59  |  0  |  0  |     100%      |\n",
    "|  T2  |  0   | 34  | 34  |      50%      |\n",
    "|  T3  |  0   | 51  |  0  |      0%       |\n",
    "| Pred | 100% | 40% | 0%  | accuracy=0.52 |\n",
    "\n",
    "34/85 = 0.4 -> 0.6\\*85 = 51\n",
    "El 0% es xq son 51 y ya los puso en la col de T2.\n",
    "accuracy = suma de diagonal/el resto.\n",
    "\n",
    "> **Nota:** Puede pedir el F1 Score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8231d377",
   "metadata": {},
   "source": [
    "# 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ba9b310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores después de la función de activación sigmoid:\n",
      "[np.float64(0.18242552380635635), np.float64(0.9820137900379085), np.float64(0.9975273768433653)]\n",
      "Valores después de la función de activación softmax:\n",
      "[4.86917893e-04 1.19144880e-01 8.80368202e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 3 -> 3 \n",
    "\n",
    "values = [-1.5, 4, 6]\n",
    "\n",
    "# a) Aplicamos la función de activación sigmoid a los valores que nos dan\n",
    "\n",
    "print(\"Valores después de la función de activación sigmoid:\")\n",
    "sigmoid_values = [1 / (1 + np.exp(-x)) for x in values]\n",
    "print(sigmoid_values)\n",
    "\n",
    "# b) Si la capa de slida en uns softmax\n",
    "\n",
    "print(\"Valores después de la función de activación softmax:\")\n",
    "exp_values = np.exp(values)\n",
    "softmax_values = exp_values / np.sum(exp_values)\n",
    "print(softmax_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267d3e94",
   "metadata": {},
   "source": [
    "# 5)\n",
    "\n",
    "#### a)\n",
    "\n",
    "Las caracteristicas que debe tener son:\n",
    "- Tener siempre valor positivo.\n",
    "- Disminuir a medida que la salida se parece a la esperada. Disminuye con la funcion de error basicamente. Esto es, acercarse a cero a medida que la salida se parece a al espera.\n",
    "\n",
    "La funcion de costo no siempre me da informacion de cuanto error tengo, eso se puede ver en la entropia cruzada binaria por ejemplo.\n",
    "\n",
    "#### b)\n",
    "\n",
    "La Entropia Cruzada Binaria es mas rapida porque no hay desvanecimiento de gradiente. La misma solo se usa con sigmoid y con clasificacion binaria.\n",
    "\n",
    "La derivada de la función que aparece en ECM hace que tarde mas. No es que no se pueda usar, solo que es mas lenta.\n",
    "\n",
    "\n",
    "#### c)\n",
    "\n",
    "No. Solo se usa con función de activación sigmoide. El perceptron da 0 o 1, y en 0 en ln no esta definido dentro de la funcion de costo de la entropia cruzada binaria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94928bbe",
   "metadata": {},
   "source": [
    "# 6)\n",
    "\n",
    "#### a)\n",
    "\n",
    "Si se usa mini-lotes se hace mas rapido con menos picos en cada mejora. \n",
    "\n",
    "\n",
    "#### b)\n",
    "\n",
    "**i.** 200 epocas, 3000/150=20 iteraciones por epoca.\n",
    "\n",
    "**ii.**se actualizaron 200*3000/150 = 200*20 = 4000.\n",
    "\n",
    "**iii.** 200*3000 = 600k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cec55f",
   "metadata": {},
   "source": [
    "# 7)\n",
    "\n",
    "#### a)\n",
    "\n",
    "\n",
    "N=32\n",
    "P=0\n",
    "K=4\n",
    "S=2\n",
    "(N+2*P-K)/S + 1 = 15\n",
    "\n",
    "15*15*8 = 1800\n",
    "\n",
    "#### b)\n",
    "\n",
    "Params = 17*8 = 392"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
