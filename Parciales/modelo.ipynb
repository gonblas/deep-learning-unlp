{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b7a6d00",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caf92bd6",
   "metadata": {},
   "source": [
    "#### a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64912f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores normalizados entre 0 y 1:\n",
      "[ 0.90188679  0.71320755 -0.11698113  0.5245283 ]\n",
      "Valores normalizados con media y desviación estándar:\n",
      "[-3.04029489 -3.04149557 -3.04677857 -3.04269625]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "MEAN = 126907\n",
    "STD = 41643\n",
    "MIN = 61\n",
    "MAX = 326\n",
    "\n",
    "values = np.array([300, 250, 30, 200], dtype=float)\n",
    "\n",
    "print(\"Valores normalizados entre 0 y 1:\")\n",
    "print((values - MIN) / (MAX - MIN))\n",
    "\n",
    "print(\"Valores normalizados con media y desviación estándar:\")\n",
    "print((values - MEAN) / STD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e3e7c3",
   "metadata": {},
   "source": [
    "#### b)\n",
    "\n",
    "Los linealizados: los valores dicen como se posicionan dentro del rango de valores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22973054",
   "metadata": {},
   "source": [
    "#### c)\n",
    "\n",
    "Los z-score: a cuantos desvios estandar estan los valores de la media."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef30598",
   "metadata": {},
   "source": [
    "#### d)\n",
    "\n",
    "La de media y desvio. Porque la linealizada sufre mucho con los valores extremos, ya que modifican como se mapean los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d3d415",
   "metadata": {},
   "source": [
    "# 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c3f99ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cálculo de la salida de un perceptrón:\n",
      "-0.4097999999999994\n",
      "Salida seleccionado:\n",
      "-0.4467999999999993\n",
      "Como ambas salidas son negativas, el perceptrón selecciona a este ejemplo.\n"
     ]
    }
   ],
   "source": [
    "W = {\n",
    "\t\"EDAD\": 0.392,\n",
    "\t\"ALTURA\": 0.001,\n",
    "\t\"HABILIDAD\": -2.441,\n",
    "\t\"BIAS\": 0.4022\n",
    "}\n",
    "\n",
    "EJEMPLO = {\n",
    "\t\"EDAD\": 10,\n",
    "\t\"ALTURA\": 150,\n",
    "\t\"HABILIDAD\": 2 # Media=2\n",
    "}\n",
    "\n",
    "#completar\n",
    "EJEMPLO_SELECCIONADO = {\n",
    "\t\"EDAD\": 16,\n",
    "\t\"ALTURA\": 202,\n",
    "\t\"HABILIDAD\": 3 # Media=2\n",
    "}\n",
    "\n",
    "#completar\n",
    "EJEMPLO_NO_SELECCIONADO = {\n",
    "\t\"EDAD\": 17,\n",
    "\t\"ALTURA\": 157,\n",
    "\t\"HABILIDAD\": 1 # Media=2\n",
    "}\n",
    "\n",
    "print(\"Cálculo de la salida de un perceptrón:\")\n",
    "salida = W[\"EDAD\"] * EJEMPLO[\"EDAD\"] + W[\"ALTURA\"] * EJEMPLO[\"ALTURA\"] + W[\"HABILIDAD\"] * EJEMPLO[\"HABILIDAD\"] + W[\"BIAS\"]\n",
    "print(salida)\n",
    "\n",
    "\n",
    "print(\"Salida seleccionado:\")\n",
    "salida_seleccionado = W[\"EDAD\"] * EJEMPLO_SELECCIONADO[\"EDAD\"] + W[\"ALTURA\"] * EJEMPLO_SELECCIONADO[\"ALTURA\"] + W[\"HABILIDAD\"] * EJEMPLO_SELECCIONADO[\"HABILIDAD\"] + W[\"BIAS\"]\n",
    "print(salida_seleccionado)\n",
    "\n",
    "print(\"Como ambas salidas son negativas, el perceptrón selecciona a este ejemplo.\")\n",
    "\n",
    "# Para saber si la salidas que dice que si o no tenemos que ver ejemplos que digan que si o no\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a54d6",
   "metadata": {},
   "source": [
    "# 2)\n",
    "\n",
    "\n",
    "Similitudes:\n",
    "- Todas calculan la salida neta de la misma forma (X*W).\n",
    "- No todas redes de una neurona.\n",
    "- Trabajan con aprendizaje supervisado.\n",
    "- Todos tienen bias.\n",
    "\n",
    "Diferencias:\n",
    "- La funcion de activacion cambia: escalon para perceptron, f(x)=x para combinador lineal y f(x)=sigmoid/tanh/etc para neurona no lineal.\n",
    "- El perceptron y neurona no lineal resuelve un problema de clasificacion. La neurona lineal solo resuleve problemas de regresion lineal.\n",
    "- El perceptron aprende de forma distinta, no usa descenso de gradiente, sino que lo hace con el vector proyeccion.\n",
    "\n",
    "> **Nota:** Podria preguntar un ejemplo de cuando funciona o no un tipo de neurona y otra. Podria preguntar por puntos en el plano y preguntar si un tipo de neurona puede funcionar o no para clasificacion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1bc520",
   "metadata": {},
   "source": [
    "# 3)\n",
    "\n",
    "## a y b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc772b0",
   "metadata": {},
   "source": [
    "|      |  T1  | T2  | T3  |    Recall     |\n",
    "| :--: | :--: | :-: | :-: | :-----------: |\n",
    "|  T1  |  59  |  0  |  0  |     100%      |\n",
    "|  T2  |  0   | 34  | 34  |      50%      |\n",
    "|  T3  |  0   | 51  |  0  |      0%       |\n",
    "| Pred | 100% | 40% | 0%  | accuracy=0.52 |\n",
    "\n",
    "34/85 = 0.4 -> 0.6\\*85 = 51\n",
    "El 0% es xq son 51 y ya los puso en la col de T2.\n",
    "accuracy = suma de diagonal/el resto.\n",
    "\n",
    "> **Nota:** Puede pedir el F1 Score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8231d377",
   "metadata": {},
   "source": [
    "# 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba9b310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores después de la función de activación sigmoid:\n",
      "[np.float64(0.18242552380635635), np.float64(0.9820137900379085), np.float64(0.9975273768433653)]\n",
      "Valores después de la función de activación softmax:\n",
      "[4.86917893e-04 1.19144880e-01 8.80368202e-01]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "values = [-1.5, 4, 6]\n",
    "\n",
    "# a) Aplicamos la función de activación sigmoid a los valores que nos dan\n",
    "\n",
    "print(\"Valores después de la función de activación sigmoid:\")\n",
    "sigmoid_values = [1 / (1 + np.exp(-x)) for x in values]\n",
    "print(sigmoid_values)\n",
    "\n",
    "# b) Si la capa de slida en uns softmax\n",
    "\n",
    "print(\"Valores después de la función de activación softmax:\")\n",
    "exp_values = np.exp(values)\n",
    "softmax_values = exp_values / np.sum(exp_values)\n",
    "print(softmax_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267d3e94",
   "metadata": {},
   "source": [
    "# 5)\n",
    "\n",
    "#### a)\n",
    "\n",
    "Las caracteristicas que debe tener son:\n",
    "- Tener siempre valor positivo.\n",
    "- Disminuir a medida que la salida se parece a la esperada. Disminuye con la funcion de error basicamente. Esto es, acercarse a cero a medida que la salida se parece a al espera.\n",
    "\n",
    "#### b)\n",
    "\n",
    "La Entropia Cruzada Binaria es mas rapida porque no hay desvanecimiento de gradiente. La misma solo se usa con sigmoid y con clasificacion binaria.\n",
    "\n",
    "La derivada de la función que aparece en ECM hace que tarde mas. No es que no se pueda usar, solo que es mas lenta.\n",
    "\n",
    "\n",
    "#### c)\n",
    "\n",
    "No. Solo se usa con función de activación sigmoide. El perceptron da 0 o 1, y en 0 en ln no esta definido dentro de la funcion de costo de la entropia cruzada binaria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94928bbe",
   "metadata": {},
   "source": [
    "# 6)\n",
    "\n",
    "#### a)\n",
    "\n",
    "Si se usa mini-lotes se hace mas rapido y con menos picos en la función de costo (en función de la cantidad de actualización de pesos). \n",
    "\n",
    "\n",
    "#### b)\n",
    "\n",
    "**i.** 200 epocas, 3000/150=20 iteraciones por epoca.\n",
    "\n",
    "**ii.**se actualizaron 200*3000/150 = 200*20 = 4000.\n",
    "\n",
    "**iii.** 200*3000 = 600k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cec55f",
   "metadata": {},
   "source": [
    "# 7)\n",
    "\n",
    "#### a)\n",
    "\n",
    "\n",
    "N=32\n",
    "P=0\n",
    "K=4\n",
    "S=2\n",
    "\n",
    "$$O = \\left\\lfloor \\frac{N+2*P-K}{S} \\right\\rfloor + 1 = 15$$\n",
    "\n",
    "$$tamaño\\_salida_{CONV2D} = 15 * 15 * 8 = 1800$$\n",
    "\n",
    "#### b)\n",
    "\n",
    "$$Params = (4^{2} + 1)\\cdot 8 = 392$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a3464",
   "metadata": {},
   "source": [
    "# Ejercicio adicional\n",
    "\n",
    "## a)\n",
    "\n",
    "La imagen de 32x32 en escala de grises pasa por:\n",
    "1. Una capa convolucional de 6 filtros de 5x5 con padding valid, dejando a la salida una imagen de 28x28 por cada uno de los 6 filtros.\n",
    "2. A esa imagen de 28x28 se le pasa un MaxPooling, que realiza una convolucion con un kernel de 2x2 y un stride de 2 dejando el maximo valor de la ventana. Esto deja una imágen de 14x14 por cada filtro.\n",
    "3. Luego, cada salida de la anterior capa pasa por una segunda capa convolucional con 16 filtros de 5x5 dejando salidas de 10x10 por cada filtro.\n",
    "4. Esta última salida pasa por una capa de MaxPolling igual a la anterior, dejando salida de 5x5.\n",
    "5. Luego de pasar por las dos capas convolucionales con sus MaxPollings, se aplanan las salidas para entrar en una red neuronal con 3 capas densas.\n",
    "\n",
    "## b)\n",
    "\n",
    "- **6 features maps 28x28:** Dado que entran imágenes de 32x32 y se tiene un padding valid (es decir, sin padding) con stride de 1 y un kernel size de 5 se obtiene:\n",
    "  $$O_1 = \\left\\lfloor \\frac{N+2*P-K}{S} \\right\\rfloor + 1 = \\left\\lfloor \\frac{32+2*0-5}{1} \\right\\rfloor + 1 = 28$$\n",
    "- **6 features maps 14x14:** Como el MaxPolling tiene un Kernel de 2 y un mismo stride (pues así funciona esta convolución), con entradas de 28x28:\n",
    "  $$O_2 = \\left\\lfloor \\frac{N+2*P-K}{S} \\right\\rfloor + 1 = \\left\\lfloor \\frac{28+2*0-2}{2} \\right\\rfloor + 1 = 14$$\n",
    "- **16 features maps 10x10:** Dado que entran imágenes de 14x14 y se tiene un padding valid (es decir, sin padding) con stride de 1 y un kernel size de 5 se obtiene:\n",
    "  $$O_3 = \\left\\lfloor \\frac{N+2*P-K}{S} \\right\\rfloor + 1 = \\left\\lfloor \\frac{14+2*0-5}{1} \\right\\rfloor + 1 = 10$$\n",
    "- **16 features maps 5x5:** Como el MaxPolling tiene un Kernel de 2 y un mismo stride (pues así funciona esta convolución), con entradas de 10x10:\n",
    "  $$O_2 = \\left\\lfloor \\frac{N+2*P-K}{S} \\right\\rfloor + 1 = \\left\\lfloor \\frac{10+2*0-2}{2} \\right\\rfloor + 1 = 4$$\n",
    "\n",
    "## c)\n",
    "\n",
    "- **Parámetros Conv_1:** Siendo 6 filtros con un kernel de 5x5:\n",
    "$$Params_{Conv\\_1} = (5^{2}\\cdot 1 + 1)\\cdot 6 = 156$$\n",
    "- **Parámetros Conv_2:** Siendo 16 filtros con un kernel de 5x5:\n",
    "$$Params_{Conv\\_2} = (5^{2}\\cdot 6 + 1)\\cdot 16 = 2416$$\n",
    "\n",
    "> **Aclaración:** Cuando se calculan los parámetros se tiene que tener en cuenta la cantidad de canales. Tener en cuenta que que el bias se suma al final una vez que se calcula el filtro para todos los canales, se suman todas las salidas y luego se suma el bias. Entonces, los parámetros tienen en cuenta los canales, pero el tamaño de salida de la capa convolucional NO (ya que se suman todos los canales para obtener la salida). \n",
    "\n",
    "## d)\n",
    "\n",
    "Puesto que en la capa de flatten se tiene como salida $16\\cdot (5^{2}) = 400$, entonces a la entrada de la red con capas densas se tiene esa cantidad de entradas.\n",
    "\n",
    "- **Dense 120 neuronas:** \n",
    "  $$Params_{Dense1} = (400+1)\\cdot 120 = 48120$$\n",
    "- **Dense 84 neuronas:** \n",
    "  $$Params_{Dense2} = (120+1)\\cdot 84 = 10164$$\n",
    "- **Dense 10 neuronas:** \n",
    "  $$Params_{Dense3} = (84+1)\\cdot 10 = 850$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de64cfad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "758ad4de",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
